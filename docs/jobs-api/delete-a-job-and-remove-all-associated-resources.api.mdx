---
id: delete-a-job-and-remove-all-associated-resources
title: "Delete a job and remove all associated resources."
description: "Delete a job and remove all associated resources."
sidebar_label: "Delete a job and remove all associated resources."
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "delete api-method"
info_path: jobs-api/speechmatics-asr-rest-api
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Delete a job and remove all associated resources."}
>
</Heading>

<MethodEndpoint
  method={"delete"}
  path={"/jobs/{jobid}"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Delete a job and remove all associated resources.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"name":"jobid","in":"path","description":"ID of the job to delete.","required":true,"example":"a1b2c3d4e5","schema":{"type":"string"}},{"name":"force","in":"query","description":"When set, a running job will be force terminated. When unset (default), a running job will not be terminated and request will return HTTP 423 Locked.","required":false,"schema":{"type":"boolean"}},{"name":"Authorization","in":"header","description":"Customer API token","required":true,"schema":{"type":"string"}},{"name":"X-SM-EAR-Tag","in":"header","description":"Early Access Release Tag","required":false,"schema":{"type":"string"}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={undefined}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"The job that was deleted.","content":{"application/json":{"schema":{"required":["job"],"properties":{"job":{"description":"Document describing a job. JobConfig will be present in JobDetails returned for GET jobs/<id> request in SaaS and in Batch Appliance, but it will not be present in JobDetails returned as item in RetrieveJobsResponse in case of Batch Appliance.","required":["created_at","data_name","id","status"],"properties":{"created_at":{"type":"string","format":"date-time","example":"2018-01-09T12:29:01.853047Z","description":"The UTC date time the job was created."},"data_name":{"type":"string","description":"Name of the data file submitted for job."},"text_name":{"type":"string","description":"Name of the text file submitted to be aligned to audio."},"duration":{"type":"integer","description":"The file duration (in seconds). May be missing for fetch URL jobs.","minimum":0},"id":{"type":"string","example":"a1b2c3d4e5","description":"The unique id assigned to the job."},"status":{"type":"string","description":"The status of the job. * `running` - The job is actively running. * `done` - The job completed successfully. * `rejected` - The job was accepted at first, but later could not be processed by the transcriber. * `deleted` - The user deleted the job. * `expired` - The system deleted the job. Usually because the job was in the `done` state for a very long time.","enum":["running","done","rejected","deleted","expired"]},"config":{"description":"JSON object that contains various groups of job configuration\nparameters. Based on the value of `type`, a type-specific object\nsuch as `transcription_config` is required to be present to\nspecify all configuration settings or parameters needed to\nprocess the job inputs as expected.\n\nIf the results of the job are to be forwarded on completion,\n`notification_config` can be provided with a list of callbacks\nto be made; no assumptions should be made about the order in\nwhich they will occur.\n\nCustomer specific job details or metadata can be supplied in\n`tracking`, and this information will be available where\npossible in the job results and in callbacks.\n","required":["type"],"properties":{"type":{"type":"string","enum":["alignment","transcription"]},"fetch_data":{"required":["url"],"properties":{"url":{"type":"string"},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the input fetch request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}}},"fetch_text":{"required":["url"],"properties":{"url":{"type":"string"},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the input fetch request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}}},"alignment_config":{"required":["language"],"properties":{"language":{"type":"string"}},"example":{"language":"en"}},"transcription_config":{"required":["language"],"properties":{"language":{"type":"string","description":"Language model to process the audio input, normally specified as an ISO language code"},"domain":{"type":"string","description":"Request a specialized model based on 'language' but optimized for a particular field, e.g. \"finance\" or \"medical\"."},"output_locale":{"type":"string","description":"Language locale to be used when generating the transcription output, normally specified as an ISO language code"},"operating_point":{"description":"Specify an operating point to use.\nOperating points change the transcription process in a high level way, such as altering the acoustic model.\nThe default is `standard`.\n  - **standard**:\n  - **enhanced**: transcription will take longer but be more accurate than 'standard'","type":"string","enum":["standard","enhanced"]},"additional_vocab":{"type":"array","x-omitempty":true,"items":{"type":"object","required":["content"],"properties":{"content":{"type":"string"},"sounds_like":{"type":"array","x-omitempty":true,"items":{"type":"string"}}}},"description":"List of custom words or phrases that should be recognized. Alternative pronunciations can be specified to aid recognition."},"punctuation_overrides":{"properties":{"sensitivity":{"type":"number","format":"float","minimum":0,"maximum":1,"description":"Ranges between zero and one. Higher values will produce more punctuation. The default is 0.5."},"permitted_marks":{"type":"array","items":{"type":"string","pattern":"^(.|all)$"},"description":"The punctuation marks which the client is prepared to accept in transcription output, or the special value 'all' (the default). Unsupported marks are ignored. This value is used to guide the transcription process."}},"description":"Control punctuation settings."},"diarization":{"type":"string","enum":["none","speaker","channel"],"description":"Specify whether speaker or channel labels are added to the transcript.\nThe default is `none`.\n  - **none**: no speaker or channel labels are added.\n  - **speaker**: speaker attribution is performed based on acoustic matching;\n             all input channels are mixed into a single stream for processing.\n  - **channel**: multiple input channels are processed individually and collated\n            into a single transcript."},"channel_diarization_labels":{"type":"array","x-omitempty":true,"items":{"type":"string","pattern":"^[A-Za-z0-9._]+$"},"description":"Transcript labels to use when using collating separate input channels."},"enable_entities":{"type":"boolean","description":"Include additional 'entity' objects in the transcription results (e.g. dates, numbers) and their original spoken form. These entities are interleaved with other types of results. The concatenation of these words is represented as a single entity with the concatenated written form present in the 'content' field. The entities contain a 'spoken_form' field, which can be used in place of the corresponding 'word' type results, in case a spoken form is preferred to a written form. They also contain a 'written_form', which can be used instead of the entity, if you want a breakdown of the words without spaces. They can still contain non-breaking spaces and other special whitespace characters, as they are considered part of the word for the formatting output. In case of a written_form, the individual word times are estimated and might not be accurate if the order of the words in the written form does not correspond to the order they were actually spoken (such as 'one hundred million dollars' and '$100 million')."},"max_delay_mode":{"type":"string","enum":["fixed","flexible"],"description":"Whether or not to enable flexible endpointing and allow the entity to continue to be spoken."},"transcript_filtering_config":{"description":"Configuration for applying filtering to the transcription","properties":{"remove_disfluencies":{"type":"boolean","description":"If true, words that are identified as disfluencies will be removed from the transcript. If false (default), they are tagged in the transcript as 'disfluency'."}}},"speaker_diarization_config":{"description":"Configuration for speaker diarization","properties":{"speaker_sensitivity":{"type":"number","format":"float","minimum":0,"maximum":1,"description":"Controls how sensitive the algorithm is in terms of keeping similar speakers separate, as opposed to combining them into a single speaker.  Higher values will typically lead to more speakers, as the degree of difference between speakers in order to allow them to remain distinct will be lower.  A lower value for this parameter will conversely guide the algorithm towards being less sensitive in terms of retaining similar speakers, and as such may lead to fewer speakers overall.  The default is 0.5."}}}},"example":{"language":"en","output_locale":"en-GB","additional_vocab":[{"content":"Speechmatics","sounds_like":["speechmatics"]},{"content":"gnocchi","sounds_like":["nyohki","nokey","nochi"]},{"content":"CEO","sounds_like":["C.E.O."]},{"content":"financial crisis"}],"diarization":"channel","channel_diarization_labels":["Caller","Agent"]}},"notification_config":{"type":"array","x-omitempty":true,"items":{"required":["url"],"properties":{"url":{"type":"string","description":"The url to which a notification message will be sent upon\ncompletion of the job. The job `id` and `status` are added\nas query parameters, and any combination of the job inputs\nand outputs can be included by listing them in `contents`.\n\nIf `contents` is empty, the body of the request will be\nempty.\n\nIf only one item is listed, it will be sent as the body of\nthe request with `Content-Type` set to an appropriate value\nsuch as `application/octet-stream` or `application/json`.\n\nIf multiple items are listed they will be sent as named file\nattachments using the multipart content type.\n\nIf `contents` is not specified, the `transcript` item will\nbe sent as a file attachment named `data_file`, for\nbackwards compatibility.\n\nIf the job was rejected or failed during processing, that\nwill be indicated by the status, and any output items that\nare not available as a result will be omitted. The body\nformatting rules will still be followed as if all items were\navailable.\n\nThe user-agent header is set to `Speechmatics-API/2.0`, or\n`Speechmatics API V2` in older API versions.\n"},"contents":{"type":"array","items":{"type":"string","enum":["jobinfo","transcript","transcript.json-v2","transcript.txt","transcript.srt","alignment","alignment.word_start_and_end","alignment.one_per_line","data","text"]},"description":"Specifies a list of items to be attached to the notification message. When multiple items are requested, they are included as named file attachments."},"method":{"type":"string","description":"The method to be used with http and https urls. The default is post.","enum":["post","put"]},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the notification request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}},"example":[{"url":"https://collector.example.org/callback","contents":["transcript:json-v2"],"auth_headers":["Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ.-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM"]}]}},"tracking":{"properties":{"title":{"type":"string","description":"The title of the job."},"reference":{"type":"string","description":"External system reference."},"tags":{"type":"array","x-omitempty":true,"items":{"type":"string"}},"details":{"type":"object","description":"Customer-defined JSON structure."}},"example":{"title":"ACME Q12018 Earnings Call","reference":"/data/clients/ACME/statements/segs/2018Q1-seg8","tags":["quick-review","segment"],"details":{"client":"ACME Corp","segment":8,"seg_start":963.201,"seg_end":1091.481}}},"output_config":{"x-omitempty":true,"type":"object","properties":{"srt_overrides":{"description":"Parameters that override default values of srt conversion. max_line_length: sets maximum count of characters per subtitle line including white space. max_lines: sets maximum count of lines in a subtitle section.","type":"object","properties":{"max_line_length":{"type":"integer"},"max_lines":{"type":"integer"}}}}},"translation_config":{"required":["target_languages"],"properties":{"target_languages":{"type":"array","maxItems":5,"items":{"type":"string"}}}},"language_identification_config":{"properties":{"expected_languages":{"type":"array","x-omitempty":true,"items":{"type":"string"}},"low_confidence_action":{"type":"string","enum":["allow","reject","use_default_language"],"description":"Action to take if all of the predicted languages are below the confidence threshold"},"default_language":{"type":"string"}}},"summarization_config":{"properties":{"content_type":{"type":"string","enum":["auto","informative","conversational"]},"summary_length":{"type":"string","enum":["brief","detailed"]},"summary_type":{"type":"string","enum":["paragraphs","bullets"]}}},"sentiment_analysis_config":{"type":"object"},"topic_detection_config":{"properties":{"topics":{"x-omitempty":true,"type":"array","items":{"type":"string"}}}},"auto_chapters_config":{"type":"object"},"audio_events_config":{"x-omitempty":true,"type":"object","properties":{"types":{"x-omitempty":true,"type":"array","items":{"type":"string"}}}}}},"lang":{"type":"string","description":"Optional parameter used for backwards compatibility with v1 api"},"errors":{"x-omitempty":true,"description":"Optional list of errors that have occurred in user interaction, for example: audio could not be fetched or notification could not be sent.","type":"array","items":{"type":"object","required":["timestamp","message"],"properties":{"timestamp":{"type":"string","example":"2021-07-14T11:53:49.242Z"},"message":{"type":"string","example":"Audio fetch error, http status 418"}}}}}}},"example":{"job":{"created_at":"2018-01-09T12:29:01.853047Z","data_name":"recording.mp3","duration":244,"id":"a1b2c3d4e5","status":"deleted","type":"transcription","transcription_config":{"language":"en","additional_vocab":[{"content":"Speechmatics","sounds_like":["speechmatics"]},{"content":"gnocchi","sounds_like":["nyohki","nokey","nochi"]},{"content":"CEO","sounds_like":["C.E.O."]},{"content":"financial crisis"}],"diarization":"channel","channel_diarization_labels":["Agent","Caller"]},"notification_config":[{"url":"https://collector.myorg.com/callback","contents":["transcript","data"],"auth_headers":["Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ.-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM"]}],"tracking":{"title":"ACME Q12018 Statement","reference":"/data/clients/ACME/statements/segs/2018Q1-seg8","tags":["quick-review","segment"],"details":{"client":"ACME Corp","segment":8,"seg_start":963.201,"seg_end":1091.481}}}}}},"application/vnd.speechmatics.v2+json":{"schema":{"required":["job"],"properties":{"job":{"description":"Document describing a job. JobConfig will be present in JobDetails returned for GET jobs/<id> request in SaaS and in Batch Appliance, but it will not be present in JobDetails returned as item in RetrieveJobsResponse in case of Batch Appliance.","required":["created_at","data_name","id","status"],"properties":{"created_at":{"type":"string","format":"date-time","example":"2018-01-09T12:29:01.853047Z","description":"The UTC date time the job was created."},"data_name":{"type":"string","description":"Name of the data file submitted for job."},"text_name":{"type":"string","description":"Name of the text file submitted to be aligned to audio."},"duration":{"type":"integer","description":"The file duration (in seconds). May be missing for fetch URL jobs.","minimum":0},"id":{"type":"string","example":"a1b2c3d4e5","description":"The unique id assigned to the job."},"status":{"type":"string","description":"The status of the job. * `running` - The job is actively running. * `done` - The job completed successfully. * `rejected` - The job was accepted at first, but later could not be processed by the transcriber. * `deleted` - The user deleted the job. * `expired` - The system deleted the job. Usually because the job was in the `done` state for a very long time.","enum":["running","done","rejected","deleted","expired"]},"config":{"description":"JSON object that contains various groups of job configuration\nparameters. Based on the value of `type`, a type-specific object\nsuch as `transcription_config` is required to be present to\nspecify all configuration settings or parameters needed to\nprocess the job inputs as expected.\n\nIf the results of the job are to be forwarded on completion,\n`notification_config` can be provided with a list of callbacks\nto be made; no assumptions should be made about the order in\nwhich they will occur.\n\nCustomer specific job details or metadata can be supplied in\n`tracking`, and this information will be available where\npossible in the job results and in callbacks.\n","required":["type"],"properties":{"type":{"type":"string","enum":["alignment","transcription"]},"fetch_data":{"required":["url"],"properties":{"url":{"type":"string"},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the input fetch request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}}},"fetch_text":{"required":["url"],"properties":{"url":{"type":"string"},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the input fetch request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}}},"alignment_config":{"required":["language"],"properties":{"language":{"type":"string"}},"example":{"language":"en"}},"transcription_config":{"required":["language"],"properties":{"language":{"type":"string","description":"Language model to process the audio input, normally specified as an ISO language code"},"domain":{"type":"string","description":"Request a specialized model based on 'language' but optimized for a particular field, e.g. \"finance\" or \"medical\"."},"output_locale":{"type":"string","description":"Language locale to be used when generating the transcription output, normally specified as an ISO language code"},"operating_point":{"description":"Specify an operating point to use.\nOperating points change the transcription process in a high level way, such as altering the acoustic model.\nThe default is `standard`.\n  - **standard**:\n  - **enhanced**: transcription will take longer but be more accurate than 'standard'","type":"string","enum":["standard","enhanced"]},"additional_vocab":{"type":"array","x-omitempty":true,"items":{"type":"object","required":["content"],"properties":{"content":{"type":"string"},"sounds_like":{"type":"array","x-omitempty":true,"items":{"type":"string"}}}},"description":"List of custom words or phrases that should be recognized. Alternative pronunciations can be specified to aid recognition."},"punctuation_overrides":{"properties":{"sensitivity":{"type":"number","format":"float","minimum":0,"maximum":1,"description":"Ranges between zero and one. Higher values will produce more punctuation. The default is 0.5."},"permitted_marks":{"type":"array","items":{"type":"string","pattern":"^(.|all)$"},"description":"The punctuation marks which the client is prepared to accept in transcription output, or the special value 'all' (the default). Unsupported marks are ignored. This value is used to guide the transcription process."}},"description":"Control punctuation settings."},"diarization":{"type":"string","enum":["none","speaker","channel"],"description":"Specify whether speaker or channel labels are added to the transcript.\nThe default is `none`.\n  - **none**: no speaker or channel labels are added.\n  - **speaker**: speaker attribution is performed based on acoustic matching;\n             all input channels are mixed into a single stream for processing.\n  - **channel**: multiple input channels are processed individually and collated\n            into a single transcript."},"channel_diarization_labels":{"type":"array","x-omitempty":true,"items":{"type":"string","pattern":"^[A-Za-z0-9._]+$"},"description":"Transcript labels to use when using collating separate input channels."},"enable_entities":{"type":"boolean","description":"Include additional 'entity' objects in the transcription results (e.g. dates, numbers) and their original spoken form. These entities are interleaved with other types of results. The concatenation of these words is represented as a single entity with the concatenated written form present in the 'content' field. The entities contain a 'spoken_form' field, which can be used in place of the corresponding 'word' type results, in case a spoken form is preferred to a written form. They also contain a 'written_form', which can be used instead of the entity, if you want a breakdown of the words without spaces. They can still contain non-breaking spaces and other special whitespace characters, as they are considered part of the word for the formatting output. In case of a written_form, the individual word times are estimated and might not be accurate if the order of the words in the written form does not correspond to the order they were actually spoken (such as 'one hundred million dollars' and '$100 million')."},"max_delay_mode":{"type":"string","enum":["fixed","flexible"],"description":"Whether or not to enable flexible endpointing and allow the entity to continue to be spoken."},"transcript_filtering_config":{"description":"Configuration for applying filtering to the transcription","properties":{"remove_disfluencies":{"type":"boolean","description":"If true, words that are identified as disfluencies will be removed from the transcript. If false (default), they are tagged in the transcript as 'disfluency'."}}},"speaker_diarization_config":{"description":"Configuration for speaker diarization","properties":{"speaker_sensitivity":{"type":"number","format":"float","minimum":0,"maximum":1,"description":"Controls how sensitive the algorithm is in terms of keeping similar speakers separate, as opposed to combining them into a single speaker.  Higher values will typically lead to more speakers, as the degree of difference between speakers in order to allow them to remain distinct will be lower.  A lower value for this parameter will conversely guide the algorithm towards being less sensitive in terms of retaining similar speakers, and as such may lead to fewer speakers overall.  The default is 0.5."}}}},"example":{"language":"en","output_locale":"en-GB","additional_vocab":[{"content":"Speechmatics","sounds_like":["speechmatics"]},{"content":"gnocchi","sounds_like":["nyohki","nokey","nochi"]},{"content":"CEO","sounds_like":["C.E.O."]},{"content":"financial crisis"}],"diarization":"channel","channel_diarization_labels":["Caller","Agent"]}},"notification_config":{"type":"array","x-omitempty":true,"items":{"required":["url"],"properties":{"url":{"type":"string","description":"The url to which a notification message will be sent upon\ncompletion of the job. The job `id` and `status` are added\nas query parameters, and any combination of the job inputs\nand outputs can be included by listing them in `contents`.\n\nIf `contents` is empty, the body of the request will be\nempty.\n\nIf only one item is listed, it will be sent as the body of\nthe request with `Content-Type` set to an appropriate value\nsuch as `application/octet-stream` or `application/json`.\n\nIf multiple items are listed they will be sent as named file\nattachments using the multipart content type.\n\nIf `contents` is not specified, the `transcript` item will\nbe sent as a file attachment named `data_file`, for\nbackwards compatibility.\n\nIf the job was rejected or failed during processing, that\nwill be indicated by the status, and any output items that\nare not available as a result will be omitted. The body\nformatting rules will still be followed as if all items were\navailable.\n\nThe user-agent header is set to `Speechmatics-API/2.0`, or\n`Speechmatics API V2` in older API versions.\n"},"contents":{"type":"array","items":{"type":"string","enum":["jobinfo","transcript","transcript.json-v2","transcript.txt","transcript.srt","alignment","alignment.word_start_and_end","alignment.one_per_line","data","text"]},"description":"Specifies a list of items to be attached to the notification message. When multiple items are requested, they are included as named file attachments."},"method":{"type":"string","description":"The method to be used with http and https urls. The default is post.","enum":["post","put"]},"auth_headers":{"type":"array","x-omitempty":true,"items":{"type":"string"},"description":"A list of additional headers to be added to the notification request when using http or https. This is intended to support authentication or authorization, for example by supplying an OAuth2 bearer token."}},"example":[{"url":"https://collector.example.org/callback","contents":["transcript:json-v2"],"auth_headers":["Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ.-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM"]}]}},"tracking":{"properties":{"title":{"type":"string","description":"The title of the job."},"reference":{"type":"string","description":"External system reference."},"tags":{"type":"array","x-omitempty":true,"items":{"type":"string"}},"details":{"type":"object","description":"Customer-defined JSON structure."}},"example":{"title":"ACME Q12018 Earnings Call","reference":"/data/clients/ACME/statements/segs/2018Q1-seg8","tags":["quick-review","segment"],"details":{"client":"ACME Corp","segment":8,"seg_start":963.201,"seg_end":1091.481}}},"output_config":{"x-omitempty":true,"type":"object","properties":{"srt_overrides":{"description":"Parameters that override default values of srt conversion. max_line_length: sets maximum count of characters per subtitle line including white space. max_lines: sets maximum count of lines in a subtitle section.","type":"object","properties":{"max_line_length":{"type":"integer"},"max_lines":{"type":"integer"}}}}},"translation_config":{"required":["target_languages"],"properties":{"target_languages":{"type":"array","maxItems":5,"items":{"type":"string"}}}},"language_identification_config":{"properties":{"expected_languages":{"type":"array","x-omitempty":true,"items":{"type":"string"}},"low_confidence_action":{"type":"string","enum":["allow","reject","use_default_language"],"description":"Action to take if all of the predicted languages are below the confidence threshold"},"default_language":{"type":"string"}}},"summarization_config":{"properties":{"content_type":{"type":"string","enum":["auto","informative","conversational"]},"summary_length":{"type":"string","enum":["brief","detailed"]},"summary_type":{"type":"string","enum":["paragraphs","bullets"]}}},"sentiment_analysis_config":{"type":"object"},"topic_detection_config":{"properties":{"topics":{"x-omitempty":true,"type":"array","items":{"type":"string"}}}},"auto_chapters_config":{"type":"object"},"audio_events_config":{"x-omitempty":true,"type":"object","properties":{"types":{"x-omitempty":true,"type":"array","items":{"type":"string"}}}}}},"lang":{"type":"string","description":"Optional parameter used for backwards compatibility with v1 api"},"errors":{"x-omitempty":true,"description":"Optional list of errors that have occurred in user interaction, for example: audio could not be fetched or notification could not be sent.","type":"array","items":{"type":"object","required":["timestamp","message"],"properties":{"timestamp":{"type":"string","example":"2021-07-14T11:53:49.242Z"},"message":{"type":"string","example":"Audio fetch error, http status 418"}}}}}}},"example":{"job":{"created_at":"2018-01-09T12:29:01.853047Z","data_name":"recording.mp3","duration":244,"id":"a1b2c3d4e5","status":"deleted","type":"transcription","transcription_config":{"language":"en","additional_vocab":[{"content":"Speechmatics","sounds_like":["speechmatics"]},{"content":"gnocchi","sounds_like":["nyohki","nokey","nochi"]},{"content":"CEO","sounds_like":["C.E.O."]},{"content":"financial crisis"}],"diarization":"channel","channel_diarization_labels":["Agent","Caller"]},"notification_config":[{"url":"https://collector.myorg.com/callback","contents":["transcript","data"],"auth_headers":["Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ.-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM"]}],"tracking":{"title":"ACME Q12018 Statement","reference":"/data/clients/ACME/statements/segs/2018Q1-seg8","tags":["quick-review","segment"],"details":{"client":"ACME Corp","segment":8,"seg_start":963.201,"seg_end":1091.481}}}}}}}},"401":{"description":"Unauthorized","content":{"application/json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}},"examples":{"response":{"value":{"code":401,"error":"Permission Denied"}}}},"application/vnd.speechmatics.v2+json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}}}}},"404":{"description":"Not found","content":{"application/json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}},"examples":{"response":{"value":{"code":404,"error":"Job not found"}}}},"application/vnd.speechmatics.v2+json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}}}}},"410":{"description":"Gone","content":{"application/json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}},"examples":{"response":{"value":{"code":410,"error":"Job Expired"}}}},"application/vnd.speechmatics.v2+json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}}}}},"423":{"description":"Locked","content":{"application/json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}},"examples":{"response":{"value":{"code":423,"error":"Resource Locked"}}}},"application/vnd.speechmatics.v2+json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}}}}},"429":{"description":"Rate Limited"},"500":{"description":"Internal Server Error","content":{"application/json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}},"examples":{"response":{"value":{"code":500,"error":"Internal Server Error"}}}},"application/vnd.speechmatics.v2+json":{"schema":{"type":"object","required":["code","error"],"properties":{"code":{"type":"integer","description":"The HTTP status code.","minimum":100},"error":{"type":"string","description":"The error message.","enum":["Bad Request","File Expired","Forbidden","Resource Locked","Format Not Supported","Internal Server Error","Job error","Job Expired","Job In Progress","Job is not of type alignment","Job is not of type transcription","Job not found","Job rejected","Job rejected due to invalid audio","Job rejected due to invalid text","Malformed request","Missing callback","Missing data_file","Missing text_file","No language selected","Not Implemented","Permission Denied","Requested product not available","Transcription not ready","Log file not available","Requested Early Access Release not available","Unprocessable Entity"]},"detail":{"type":"string","description":"The details of the error."}}}}}},"503":{"description":"Service Unavailable"}}}
>
  
</StatusCodes>


      