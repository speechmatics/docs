---
description: "Translate your audio into multiple languages with a single API call."
keywords:
  [
    speechmatics,
    features,
    translation,
    transcription,
    speech recognition,
    automatic speech recognition,
    asr,
    speech translation,
    speech-to-text translation,
    real-time speech translation,
  ]
sidebar_position: 1
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import SchemaNode from "@theme/Schema";
import realtimeSchema from "!asyncapi-schema-loader!@site/spec/realtime.yaml";
import transcriptResponseSchema from "!openapi-schema-loader!@site/spec/batch.yaml"

# Translation

Translate your audio into multiple languages through a single API call, with over 30 languages supported.

## Use cases

- Translate audio files for international distribution
- Power live subtitles and captions for global events
- Build voice assistants or AI agents that communicate in multiple languages

## Configuration

Enable translation when processing a file or in real-time in SaaS and [on-prem deployment](/deployments/container/gpu-translation).

New to Speechmatics? See our guides on [transcribing a file](/speech-to-text/batch/quickstart) or [transcribing in real-time](/speech-to-text/real-time/quickstart). Once set up, add the following configuration to enable translation:

```json
{
  "type": "transcription",
  "transcription_config": {
    "operating_point": "enhanced",
    "language": "en"
  },
  // highlight-start
  "translation_config": {
    "target_languages": ["es", "de"],
    "enable_partials": true
  }
  // highlight-end
}
```

:::tip
You can configure up to five translation languages at a time.
:::

## Batch output

The returned JSON will include a new property called `translations`, which contains a list of translated text for each target language requested (using the same [ISO language codes](/speech-to-text/supported-languages#languages) as for transcription).

<SchemaNode schema={transcriptResponseSchema.definitions.RetrieveTranscriptResponse} />

An example of the response is below:

```json
{
    "format": "2.9",
    "job": {
        "created_at": "2023-01-23T19:31:19.354Z",
        "data_name": "example.wav",
        "duration": 15,
        "id": "ggqjaazkqf"
    },
    "metadata": {
        "created_at": "2023-01-23T19:31:44.766Z",
        "type": "transcription",
        "transcription_config": {
            "language": "en",
            "diarization": "speaker"
        },
        "translation_config": {
            "target_languages": [
                "es"
            ]
        }
    },
    "results": [
        {
            "start_time": 0.78,
            "end_time": 1.32,
            "type": "word",
            "alternatives": [
                {
                    "content": "Welcome",
                    "confidence": 1.0,
                    "language": "en",
                    "speaker": "S1"
                }
            ]
        },
        ...
    ],
    "translations": {
        "es": [
            {
                "start_time": 0.78,
                "end_time": 2.58,
                "content": "Bienvenidos a Speechmatics.",
                "speaker": "S1"
            },
            {
                "start_time": 3.0,
                "end_time": 7.94,
                "content": "Esperamos que tengas un gran d√≠a.",
                "speaker": "S1"
            },
            ...
        ]
      }
}
```

## Realtime output

Realtime provides a stream of translation messages per language requested. Translation messages will arrive after transcription messages, but won't delay transcription. Realtime translations have the following schema:

<SchemaNode schema={realtimeSchema.components.schemas.AddTranslation} />

Translations arrive as lower latency partial results and higher latency, more accurate finals.

### Partials

Partial translations typically correspond to unfinished sentences and have lower latency than final translations. By default, only final translations are produced. Enable partials using the `enable_partials` property in `translation_config` for the session. For example:

```json
{
  "format": "2.9",
  "message": "AddPartialTranslation",
  "language": "es",
  "results": [
    {
      "start_time": 5.45999987795949,
      "end_time": 5.889999870583415,
      "content": "Bienvenidos a",
      "speaker": "S1"
    }
  ]
}
```

### Finals

Final translations are the most accurate and complete translations, usually at the end of a sentence. These translations are considered final and will not be updated afterwards. For example:

```json
{
  "format": "2.9",
  "message": "AddTranslation",
  "language": "es",
  "results": [
    {
      "start_time": 5.45999987795949,
      "end_time": 6.189999870583415,
      "content": "Bienvenidos a Speechmatics.",
      "speaker": "S1"
    }
  ]
}
```

## Examples

<Tabs groupId="transcription-types">
  <TabItem value="batch" label="Batch Translation" default>
Python client example to translate a file for batch.

```python showLineNumbers
from speechmatics.models import ConnectionSettings
from speechmatics.batch_client import BatchClient
from httpx import HTTPStatusError

API_KEY = "YOUR_API_KEY"
PATH_TO_FILE = "example.wav"
LANGUAGE = "en" # Transcription language
TRANSLATION_LANGUAGES = ["es","de"]

settings = ConnectionSettings(
    url="https://asr.api.speechmatics.com/v2",
    auth_token=API_KEY,
)

# Define transcription parameters
conf = {
    "type": "transcription",
    "transcription_config": {
        "language": LANGUAGE
    },
    "translation_config": {
        "target_languages":TRANSLATION_LANGUAGES
    }
}

# Open the client using a context manager
with BatchClient(settings) as client:
    try:
        job_id = client.submit_job(
            audio=PATH_TO_FILE,
            transcription_config=conf,
        )
        print(f'job {job_id} submitted successfully, waiting for transcript')

        # Note that in production, you should set up notifications instead of polling.
        # Notifications are described here: https://docs.speechmatics.com/features-other/notifications
        transcript = client.wait_for_completion(job_id, transcription_format='json-v2')
        for language in TRANSLATION_LANGUAGES:
          # Print the translation for each language from the JSON
          print(f"Translation for {language}")
          translation = ""
          for translated_segment in transcript["translations"][language]:
              translation += translated_segment["content"] + " "
          print(translation)
    except HTTPStatusError as e:
        if e.response.status_code == 401:
            print('Invalid API key - Check your API_KEY at the top of the code!')
        elif e.response.status_code == 400:
            print(e.response.json()['detail'])
        else:
            raise e
```

</TabItem>
  <TabItem value="real-time" label="Real-Time Translation">

Python client example to translate a file in real-time, see [here](/speech-to-text/realtime/quickstart) for more examples of Real-Time Transcription

```python showLineNumbers
import speechmatics
from httpx import HTTPStatusError

API_KEY = "YOUR_API_KEY"
PATH_TO_FILE = "example.wav"
LANGUAGE = "en" # Transcription language
TRANSLATION_LANGUAGES = ["es","de"]
CONNECTION_URL = f"wss://eu2.rt.speechmatics.com/v2/{LANGUAGE}"

# Create a transcription client
ws = speechmatics.client.WebsocketClient(
    speechmatics.models.ConnectionSettings(
        url=CONNECTION_URL,
        auth_token=API_KEY,
    )
)

# Define an event handler to print the translations
def print_translation(msg):
    msg_type="Final"
    if msg['message'] == "AddPartialTranslation":
        msg_type="Partial"

    language = msg['language'] # language for translation message
    translations = []
    for translation_segment in msg['results']:
        translations.append(translation_segment['content'])

    translation = " ".join(translations).strip()
    print(f"{msg_type} translation for {language}: {translation}")

# Register the event handler for partial translation
ws.add_event_handler(
    event_name=speechmatics.models.ServerMessageType.AddPartialTranslation,
    event_handler=print_translation,
)

# Register the event handler for full translation
ws.add_event_handler(
    event_name=speechmatics.models.ServerMessageType.AddTranslation,
    event_handler=print_translation,
)

settings = speechmatics.models.AudioSettings()

# Define transcription parameters with translation
# Full list of parameters described here: https://speechmatics.github.io/speechmatics-python/models

translation_config = speechmatics.models.RTTranslationConfig(
    target_languages=TRANSLATION_LANGUAGES,
    #enable_partials=True # Optional argument to provide translation of partial sentences
)

transcription_config = speechmatics.models.TranscriptionConfig(
    language=LANGUAGE,
    translation_config=translation_config
)

print("Starting transcription (type Ctrl-C to stop):")
with open(PATH_TO_FILE, 'rb') as fd:
    try:
        ws.run_synchronously(fd, transcription_config, settings)
    except KeyboardInterrupt:
        print("\nTranscription stopped.")
    except HTTPStatusError as e:
        if e.response.status_code == 401:
            print('Invalid API key - Check your API_KEY at the top of the code!')
        else:
            raise e
```

  </TabItem>
</Tabs>

## Languages

The following languages can be translated to and from **English** in realtime and batch:

- Bulgarian (bg)
- Catalan (ca)
- Mandarin (cmn)
- Czech (cs)
- Danish (da)
- German (de)
- Greek (el)
- Spanish (es)
- Estonian (et)
- Finnish (fi)
- French (fr)
- Galician (gl)
- Hindi (hi)
- Croatian (hr)
- Hungarian (hu)
- Indonesian (id)
- Italian (it)
- Japanese (ja)
- Korean (ko)
- Lithuanian (lt)
- Latvian (lv)
- Malay (ms)
- Dutch (nl)
- Norwegian (no)
- Polish (pl)
- Portuguese (pt)
- Romanian (ro)
- Russian (ru)
- Slovakian (sk)
- Slovenian (sl)
- Swedish (sv)
- Turkish (tr)
- Ukrainian (uk)
- Vietnamese (vi)

:::tip
In batch, you can also translate from Norwegian Bokm√•l to Nynorsk.
:::

## Best practices

Follow these guidelines to achieve optimal translation results:

- **Use enhanced operating point** ‚Äî Higher transcription accuracy directly leads to better translations
- **Keep punctuation enabled** ‚Äî Maintain all [punctuation settings](/speech-to-text/formatting#punctuation) at default levels for optimal translation quality
- **Consider processing times** ‚Äî Each additional target language increases processing time in batch jobs
- **Plan for connection closing** ‚Äî Realtime sessions may have a 5-second delay when finalizing translations

:::warning
Be aware of these limitations:
- **Language limit** ‚Äî Maximum 5 target languages per transcription
- **Format restrictions** ‚Äî Only JSON format includes translations (text and SRT formats contain source language only)
- **Reduced metadata** ‚Äî Certain features (timestamps, confidence scores, word tagging, and regional spelling) are only available in the original language
:::

## Next Steps

- [Try the portal](https://portal.speechmatics.com/) to see how translation works with your own audio.
- Use [diarization](/speech-to-text/features/diarization) to enhance your translations with speaker information.
