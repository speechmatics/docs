import Admonition from '@theme/Admonition';
import CodeBlock from '@theme/CodeBlock';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

import javascriptRadioExample from "./assets/javascript-radio-example.js?raw"
import pythonRadioExample from "./assets/url-example.py?raw"

# Quickstart

Learn how to convert streaming audio to text.

This guide will show you how to use WebSocket API to transcribe voice.

:::tip
The easiest way to try real-time transcription is via the [web portal](https://portal.speechmatics.com/jobs/create/real-time).
:::

## Using the Real-time SaaS WebSocket API

### 1. Create an API key

[Create an API key in the portal here](https://portal.speechmatics.com/settings/api-keys), which you'll use to securely access the API.
Store the key as a managed secret.

:::info
Enterprise customers may need to speak to [Support](https://support.speechmatics.com) to get your API keys.
:::

### 2. Pick and install a library

Check out our [Javascript client](https://www.npmjs.com/package/@speechmatics/real-time-client) or [Python client](https://pypi.org/project/speechmatics-python/) to get started.

<Tabs groupId="language">
  <TabItem value="javascript" label="Javascript">
    ```
    npm install @speechmatics/real-time-client @speechmatics/auth
    ```
  </TabItem>
  <TabItem value="python" label="Python">
    ```
    pip3 install speechmatics-python
    ```
  </TabItem>
</Tabs>


### 3. Insert your API key

Paste your API key into `YOUR_API_KEY` in the code.

<Tabs groupId="language">
  <TabItem value="javascript" label="Javascript">
    <CodeBlock language="javascript">
      {javascriptRadioExample}
    </CodeBlock>
  </TabItem>
  <TabItem value="python" label="Python">
    <CodeBlock language="python">
      {pythonRadioExample}
    </CodeBlock>
  </TabItem>
</Tabs>



## Transcript outputs

The API returns transcripts in JSON format. You can receive two types of output: [Final](#final-transcripts) and [Partial](#partial-transcripts) transcripts. Choose the type based on your latency and accuracy needs.

### Final transcripts

Final transcripts are the definitive result.
- They reflect the best transcription for the spoken audio.
- Once displayed, they are not updated.
- Words arrive incrementally, with some delay.

You control the latency and accuracy tradeoff [using the `max_delay` setting](/speech-to-text/realtime/output#latency) in your `transcription_config`.
Larger values of `max_delay` increase accuracy by giving the system more time to process audio context.

:::tip
Best for accurate, completed transcripts where some delay is acceptable
:::

### Partial transcripts

Partial transcripts are low-latency and can update later as more conversation context arrives.
- You must enable them using `enable_partials` in your `transcription_config`.
- Partials are emitted quickly (typically less than 500ms).
- The engine may revise them as more audio is processed.

You can combine partials with finals for a responsive user experience — show partials first, then replace them with finals as they arrive.

You control the latency and accuracy tradeoff using the [`max_delay` setting](/speech-to-text/realtime/output#latency) in your `transcription_config`.

:::tip
Use partials for: real-time captions, voice interfaces, or any case where speed matters
:::
