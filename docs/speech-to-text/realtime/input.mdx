---
description: 'Learn about the supported input audio formats for the Speechmatics Realtime API'
keywords: [speechmatics, transcription, speech recognition, asr, api, limits]
toc_max_heading_level: 2
sidebar_position: 2
---

import HTTPMethodBadge from '@site/src/theme/HTTPMethodBadge'
import SchemaNode from '@theme/Schema'
import realtimeSchema from "!asyncapi-schema-loader!@site/spec/realtime.yaml"

# Input

## Supported input audio formats
Sessions can be configured to use two types of audio input: `file` and `raw`.  
We recommend using the `raw` option, unless you have a specific reason to use the `file` option.

:::tip
For capturing raw audio in the browser, try our [`browser-audio-input` package](https://www.npmjs.com/package/@speechmatics/browser-audio-input).
:::

### `audio_format`

The format must be supplied in the `audio_format` field of the `StartRecognition` message. See the [API reference](/api-ref/realtime-transcription-websocket#startrecognition).

<SchemaNode schema={realtimeSchema.components.schemas.AudioFormat} />

## Sending audio

After receiving a `RecognitionStarted` message, you can start sending audio over the Websocket connection. Audio is sent as binary data, encoded in the format specified in the `StartRecognition` message. See [Protocol overview](/api-ref/realtime-transcription-websocket#protocol-overview) for complete details of the API protocol.

## Next steps

View our guides: 
- [using a microphone](docs/speech-to-text/realtime/guides/python-using-microphone.mdx) to learn how to capture audio from a microphone. 
- [using FFMPEG](docs/speech-to-text/realtime/guides/python-using-ffmpeg.mdx) to find out how to pipe microphone audio to the API.