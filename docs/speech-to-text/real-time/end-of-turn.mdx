---
description: 'Create responsive voice applications with end of turn detection'
keywords:
  [
    speechmatics,
    end of utterance,
    end of turn,
    transcription,
    speech recognition,
    asr,
    voice ai,
    conversation,
    turn-taking
  ]
---
import CodeBlock from "@theme/CodeBlock";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import eouStreamingPythonExample from "./assets/end-of-utterance-streaming-example.py"
import eouFilePythonExample from "./assets/end-of-utterance-file-example.py"

# End of turn detection

Build responsive voice applications by detecting when users finish speaking.

## Benefits

- Create natural conversational experiences with proper turn-taking
- Reduce response latency in voice assistants and chatbots
- Improve user experience with timely system responses
- Enable more human-like interactions in voice applications

## Use cases

* **Voice AI** - Detect when to generate responses in conversational agents
* **Real-time translation** - Deliver translations as soon as speakers complete thoughts
* **Dictation** - Determine when users have finished speaking to finalize transcription

## How it works

Speechmatics offers two complementary approaches to detect when a speaker has finished their turn:

1. **Silence-based detection** - Identifies pauses between speech
2. **Semantic detection** - Analyzes linguistic context to identify natural endpoints

## Silence-based detection

Detect natural pauses in speech by configuring the silence threshold in your transcription request.

### Configuration

Add the `end_of_utterance_silence_trigger` parameter to your [StartRecognition](/api-ref/realtime-transcription-websocket#startrecognition) message:

```json
{
  "type": "transcription",
  "transcription_config": {
    "conversation_config": {
      "end_of_utterance_silence_trigger": 0.5
    },
    "language": "en"
  }
}
```

The `end_of_utterance_silence_trigger` parameter specifies the silence duration (0-2s) that triggers end of utterance detection.

:::info
Setting `end_of_utterance_silence_trigger` to 0 disables detection.
:::

### Recommended settings

- **Voice AI applications**: 0.5-0.8 seconds
- **Dictation applications**: 0.8-1.2 seconds

### Response format

When an end of utterance is detected, you'll receive:

1. A [`Final` transcript](/speech-to-text/real-time/quickstart#final-transcripts) message
2. An `EndOfUtterance` message

```json
{
  "message": "EndOfUtterance",
  "format": "2.9",
  "metadata": {
    "start_time": 1.07,
    "end_time": 1.07
  }
}
```

:::tip
  - Keep `end_of_utterance_silence_trigger` lower than the `max_delay` value
  - Messages are only sent after speech is recognized
  - Duplicate messages are never sent for the same silence period
  - Messages don't contain speaker information from [diarization](/speech-to-text/output-enhancements/diarization)
:::

## Semantic end of turn 

For more natural conversations, combine silence detection with linguistic context analysis. This approach understands when a speaker has completed their thought based on the content of their speech.

Semantic end of turn detection is available through our [Flow service](/voice-agents-flow), which combines multiple signals for optimal turn detection:

- Silence duration
- Linguistic completeness
- Question detection
- Prosodic features

Try semantic end of turn detection with our free [Flow service demo](https://www.speechmatics.com/flow) or read our [implementation guide](https://blog.speechmatics.com/semantic-turn-detection).

## Code examples

<Tabs groupId="eou-examples">
    <TabItem value="streaming" label="Python - Live streaming">

      Real-time streaming from microphone - ideal for voice AI applications.

      <CodeBlock language="python" showLineNumbers>
      {eouStreamingPythonExample}
      </CodeBlock>

    </TabItem>
    <TabItem value="file" label="Python - File">

    Copy in your API key and file name to get started.

    <CodeBlock language="python" showLineNumbers>
      {eouFilePythonExample}
    </CodeBlock>

    </TabItem>
</Tabs>
